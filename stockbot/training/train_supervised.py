"""Supervised learning training script for StockBot.

This script trains a simple LSTM network (or other classifier/regressor) on
historical OHLCV data with technical indicators to predict future price
movement.  It can be executed from the command line or imported as a
module.  It expects a CSV file generated by
`stockbot.ingestion.feature_engineering.prepare_dataset()`.

Usage (command line):

    python -m stockbot.training.train_supervised --dataset ./stockbot/data/AAPL_2020-01-01_to_2024-12-31_window10.csv \
        --epochs 10 --batch-size 64 --model-out ./stockbot/models/aapl_lstm.pt

The script prints training/validation loss and accuracy for monitoring.

Note: PyTorch must be installed to run this script.  If PyTorch is not
available in your environment, you can still read the code and adapt it
inside your own project.  The script is intended as a template and can
be modified to accommodate different architectures (e.g., Transformer,
XGBoost, Random Forest) or objectives (e.g., regression).
"""

from __future__ import annotations

import argparse
import os
from typing import Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset
except ImportError as exc:
    raise ImportError(
        "PyTorch is required to run the supervised training script. "
        "Install with `pip install torch`."
    ) from exc

from stockbot.ingestion.feature_engineering import create_sliding_windows


class LSTMClassifier(nn.Module):
    """A simple LSTM network for binary classification.

    It takes sequences of shape (batch, window_size, num_features) and
    outputs logits of shape (batch, 2).  You can adjust hidden size or
    add more layers to improve performance.
    """

    def __init__(self, num_features: int, hidden_size: int = 64, num_layers: int = 1):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=num_features,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
        )
        self.fc = nn.Linear(hidden_size, 2)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x shape: (batch, seq_len, num_features)
        output, _ = self.lstm(x)
        # Take the output of the last timestep
        last_out = output[:, -1, :]
        logits = self.fc(last_out)
        return logits


def load_dataset(csv_path: str, window_size: int) -> Tuple[np.ndarray, np.ndarray]:
    """Load a dataset CSV and create sliding windows with labels.

    Args:
        csv_path: Path to the CSV produced by prepare_dataset().
        window_size: Length of each input sequence.

    Returns:
        Tuple (X, y) where X is an array of shape (N, window_size, num_features)
        and y is an array of labels of shape (N,).
    """
    df = pd.read_csv(csv_path, index_col=0)
    # Determine which columns to use as features.  Exclude label and the
    # original OHLCV columns to avoid leakage.  Here we include only
    # engineered indicators plus log_return.
    feature_cols = [
        col
        for col in df.columns
        if col not in ["Open", "High", "Low", "Close", "Adj Close", "Volume", "label"]
    ]
    X, y = create_sliding_windows(df, feature_columns=feature_cols, window_size=window_size)
    return X, y


def train(
    model: nn.Module,
    dataloader: DataLoader,
    loss_fn: nn.Module,
    optimizer: torch.optim.Optimizer,
) -> float:
    """Run one epoch of training.

    Args:
        model: LSTM classifier.
        dataloader: DataLoader yielding batches of (inputs, targets).
        loss_fn: Loss function (e.g., CrossEntropyLoss).
        optimizer: Optimizer (e.g., Adam).

    Returns:
        Average loss for the epoch.
    """
    model.train()
    total_loss = 0.0
    for batch_x, batch_y in dataloader:
        optimizer.zero_grad()
        logits = model(batch_x)
        loss = loss_fn(logits, batch_y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * batch_x.size(0)
    return total_loss / len(dataloader.dataset)


def evaluate(model: nn.Module, dataloader: DataLoader) -> Tuple[float, float]:
    """Evaluate model on a validation or test set.

    Returns:
        Tuple (average_loss, accuracy).
    """
    model.eval()
    loss_fn = nn.CrossEntropyLoss()
    total_loss = 0.0
    preds, targets = [], []
    with torch.no_grad():
        for batch_x, batch_y in dataloader:
            logits = model(batch_x)
            loss = loss_fn(logits, batch_y)
            total_loss += loss.item() * batch_x.size(0)
            preds.append(torch.argmax(logits, dim=1).cpu().numpy())
            targets.append(batch_y.cpu().numpy())
    preds = np.concatenate(preds)
    targets = np.concatenate(targets)
    acc = accuracy_score(targets, preds)
    avg_loss = total_loss / len(dataloader.dataset)
    return avg_loss, acc


def main():
    parser = argparse.ArgumentParser(description="Train an LSTM classifier on stock data")
    parser.add_argument("--dataset", required=True, help="Path to CSV dataset")
    parser.add_argument("--window-size", type=int, default=10, help="Sequence length for inputs")
    parser.add_argument("--epochs", type=int, default=10, help="Number of training epochs")
    parser.add_argument("--batch-size", type=int, default=64, help="Training batch size")
    parser.add_argument("--hidden-size", type=int, default=64, help="Hidden size of the LSTM")
    parser.add_argument("--learning-rate", type=float, default=1e-3, help="Learning rate")
    parser.add_argument("--model-out", default="lstm_model.pt", help="Path to save the trained model")
    args = parser.parse_args()

    # Load data and create sliding windows
    X, y = load_dataset(args.dataset, args.window_size)
    # Split into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    # Convert to torch tensors
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
    y_train_t = torch.tensor(y_train, dtype=torch.long).to(device)
    X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)
    y_val_t = torch.tensor(y_val, dtype=torch.long).to(device)
    train_dataset = TensorDataset(X_train_t, y_train_t)
    val_dataset = TensorDataset(X_val_t, y_val_t)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size)
    # Initialize model
    num_features = X.shape[2]
    model = LSTMClassifier(num_features=num_features, hidden_size=args.hidden_size).to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)
    # Training loop
    for epoch in range(1, args.epochs + 1):
        train_loss = train(model, train_loader, loss_fn, optimizer)
        val_loss, val_acc = evaluate(model, val_loader)
        print(
            f"Epoch {epoch}/{args.epochs} - "
            f"train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}"
        )
    # Final evaluation
    val_loss, val_acc = evaluate(model, val_loader)
    print("Validation Accuracy:", val_acc)
    print("Classification Report:\n", classification_report(y_val, np.argmax(
        [m.cpu().detach().numpy() for m in model(X_val_t)], axis=1)))
    # Save model
    model_dir = os.path.dirname(args.model_out)
    if model_dir:
        os.makedirs(model_dir, exist_ok=True)
    torch.save(model.state_dict(), args.model_out)
    print(f"Model saved to {args.model_out}")


if __name__ == "__main__":
    main()
